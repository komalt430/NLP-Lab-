{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!python -m nltk.downloader maxent_ne_chunker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7nXh1eAiRjI",
        "outputId": "4a77a5c2-01a5-4081-9f41-b5fbcf7d04a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n",
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('words')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNkb7yJVilPi",
        "outputId": "294c29be-2085-43ab-9ad0-a95dd1fa83a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.chunk import ne_chunk\n",
        "\n",
        "\n",
        "def named_entity_recognition(sentence):\n",
        "    words = word_tokenize(sentence) # Step 1: Tokenization\n",
        "    tagged_words = pos_tag(words)   # Step 2: Part-of-speech (POS) Tagging\n",
        "    named_entities = ne_chunk(tagged_words) # Step 3: Named Entity Recognition (NER)\n",
        "    return named_entities\n",
        "\n",
        "sentence = \"Barack Obama was born in Hawaii on August 4, 1961.\"\n",
        "entities = named_entity_recognition(sentence)\n",
        "\n",
        "\n",
        "for entity in entities:\n",
        "    if isinstance(entity, nltk.tree.Tree):\n",
        "        entity_type = entity.label()\n",
        "        entity_text = \" \".join([word for word, _ in entity.leaves()])\n",
        "        print(f\"Entity: {entity_text}, Type: {entity_type}\")"
      ],
      "metadata": {
        "id": "eTUR3a1O98zG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ade593-b1b7-4cc1-8f05-1af6297ddbe6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: Barack, Type: PERSON\n",
            "Entity: Obama, Type: PERSON\n",
            "Entity: Hawaii, Type: GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dmFdMO9rmCm3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}